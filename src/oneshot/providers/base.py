from abc import ABC, abstractmethod
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Optional, Dict, Any, List, Tuple, Generator

from ..constants import WORKER_SYSTEM_PROMPT, AUDITOR_SYSTEM_PROMPT, REWORKER_SYSTEM_PROMPT

@dataclass
class RecoveryResult:
    """
    Result of an executor recovery operation.

    Attributes:
        success (bool): Whether recovery was successful
        recovered_activity (List[Any]): Activities recovered from external state
        verdict (Optional[str]): Human-readable verdict (e.g., "DONE", "INCOMPLETE")
    """
    success: bool
    recovered_activity: List[Any]
    verdict: Optional[str] = None

@dataclass
class ExecutionResult:
    """
    Represents the result of an autonomous executor task.

    Attributes:
        success (bool): Indicates if the task was executed successfully
        output (str): The output generated by the task
        error (Optional[str]): Any error message if the task failed
        git_commit_hash (Optional[str]): Git commit hash if applicable
        metadata (Dict[str, Any]): Additional metadata about the execution
    """
    success: bool
    output: str
    error: Optional[str] = None
    git_commit_hash: Optional[str] = None
    metadata: Dict[str, Any] = None

class BaseExecutor(ABC):
    """
    Abstract base class for autonomous executor providers.

    Defines the common interface and core methods that all executor providers
    must implement. Each executor encapsulates command construction, activity
    parsing, and output formatting specific to its agent type.

    Phase 4 Enhancement: Adds context manager streaming interface for resource management.
    """

    @contextmanager
    @abstractmethod
    def execute(self, prompt: str) -> Generator[str, None, None]:
        """
        Execute a task and yield streaming output.

        Context manager that yields a generator/stream of output from the executor.
        Automatically handles resource cleanup (process termination) on exit.

        Args:
            prompt (str): The task prompt to execute

        Yields:
            str: Streaming output from the executor

        Raises:
            Any exceptions from the executor process

        Example:
            with executor.execute("task") as stream:
                for line in stream:
                    print(line)
            # Process is automatically cleaned up here
        """
        pass

    @abstractmethod
    def recover(self, task_id: str) -> RecoveryResult:
        """
        Recover activity from external state (forensic analysis).

        Analyzes filesystem, logs, or other external state to salvage a dead session.
        Useful for resuming interrupted tasks or analyzing failed runs.

        Args:
            task_id (str): Identifier for the task to recover

        Returns:
            RecoveryResult: Result of recovery attempt with recovered activities
        """
        pass

    @abstractmethod
    def run_task(self, task: str) -> ExecutionResult:
        """
        Execute a given task using the specific provider.

        Args:
            task (str): The task description or command to execute

        Returns:
            ExecutionResult: Detailed result of the task execution
        """
        pass

    @abstractmethod
    def build_command(self, prompt: str, model: Optional[str] = None) -> List[str]:
        """
        Build executor-specific CLI command for invoking the agent.

        Args:
            prompt (str): The task prompt to send to the executor
            model (Optional[str]): Optional model specification for executors that support it

        Returns:
            List[str]: Command and arguments as a list for subprocess execution
        """
        pass

    @abstractmethod
    def parse_streaming_activity(self, raw_output: str) -> Tuple[str, Dict[str, Any]]:
        """
        Parse streaming output from the executor into structured results.

        Interprets agent-specific output format (JSON stream, text patterns, etc.)
        and extracts meaningful activity information.

        Args:
            raw_output (str): Raw streaming output from executor

        Returns:
            Tuple[str, Dict[str, Any]]: (stdout_summary, auditor_details_dict)
                - stdout_summary: Human-readable summary of the execution
                - auditor_details_dict: Structured details for audit logging
        """
        pass

    @abstractmethod
    def get_provider_name(self) -> str:
        """
        Get the executor type identifier.

        Returns:
            str: Executor type name (e.g., "cline", "claude", "gemini", "aider", "direct")
        """
        pass

    @abstractmethod
    def get_provider_metadata(self) -> Dict[str, Any]:
        """
        Get provider-specific configuration metadata.

        Returns:
            Dict[str, Any]: Metadata dictionary with executor-specific configuration
                - Should include type, capabilities, constraints, etc.
        """
        pass

    @abstractmethod
    def should_capture_git_commit(self) -> bool:
        """
        Indicate whether this executor produces git commits that should be captured.

        Returns:
            bool: True if executor creates git commits (Cline, Claude, Aider)
                  False if it doesn't (Gemini, Direct)
        """
        pass

    def _sanitize_environment(self, env: Dict[str, str]) -> Dict[str, str]:
        """
        Sanitize environment variables to remove sensitive information.

        Args:
            env (Dict[str, str]): Original environment variables

        Returns:
            Dict[str, str]: Sanitized environment variables
        """
        # Remove common API key and secret environment variables
        sensitive_keys = [
            'OPENAI_API_KEY',
            'ANTHROPIC_API_KEY',
            'GOOGLE_APPLICATION_CREDENTIALS',
            'ANTHROPIC_API_SECRET',
            'OPENAI_API_SECRET'
        ]

        return {
            k: '***REDACTED***' if k in sensitive_keys else v
            for k, v in env.items()
        }

    def _strip_ansi_colors(self, text: str) -> str:
        """
        Remove ANSI color codes from terminal output.

        Args:
            text (str): Input text with potential ANSI color codes

        Returns:
            str: Text with color codes stripped
        """
        import re
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        return ansi_escape.sub('', text)

    def get_system_instructions(self, role: str) -> str:
        """
        Get system instructions for a specific role.

        Default implementation provides XML-based instructions for backward compatibility.

        Args:
            role (str): Role type ("worker", "auditor", or "reworker")

        Returns:
            str: System instructions for the specified role
        """
        if role == "worker":
            return WORKER_SYSTEM_PROMPT
        elif role == "auditor":
            return AUDITOR_SYSTEM_PROMPT
        elif role == "reworker":
            return REWORKER_SYSTEM_PROMPT
        else:
            raise ValueError(f"Unknown role: {role}")

    def format_prompt(self, task: str, role: str, header: Optional[str] = None, context: Optional[Dict] = None) -> str:
        """
        Format a complete prompt for the executor.

        Default implementation provides XML-based formatting for backward compatibility.

        Args:
            task (str): The main task description
            role (str): Role type ("worker", "auditor", or "reworker")
            header (Optional[str]): Custom header for the prompt
            context (Optional[Dict]): Context dictionary containing iteration info, feedback, etc.

        Returns:
            str: Formatted prompt string
        """
        context = context or {}
        system_instructions = self.get_system_instructions(role)

        if role == "worker" or role == "reworker":
            return self._format_worker_prompt(task, role, header, context, system_instructions)
        elif role == "auditor":
            return self._format_auditor_prompt(task, header, context, system_instructions)
        else:
            raise ValueError(f"Unknown role: {role}")

    def _format_worker_prompt(self, task: str, role: str, header: str, context: Dict, system_instructions: str) -> str:
        """Format worker/reworker prompt with XML structure."""
        header = header or "oneshot execution"

        # Build header with completion guidance
        header_template = f"""{header}

IMPORTANT: Provide your final answer in valid JSON format when possible. Include completion indicators like "DONE", "success", or "status" even in non-JSON responses.

PREFERRED FORMAT (valid JSON):
{{
  "status": "DONE",
  "result": "<your answer/output here>",
  "confidence": "<high/medium/low>",
  "validation": "<how you verified this answer - sources, output shown, reasoning explained>",
  "execution_proof": "<what you actually did - optional if no external tools were used>"
}}

ALTERNATIVE: If JSON is difficult, include clear completion indicators:
- Words like "DONE", "success", "completed", "finished"
- Status/result fields even in malformed JSON
- Clear indication that the task is complete

IMPORTANT GUIDANCE:
- "result" should be your final answer
- "validation" should describe HOW you got it (tools used, sources checked, actual output if execution)
- "execution_proof" is optional - only include if you used external tools, commands, or computations
- For knowledge-based answers: brief validation is sufficient
- For coding tasks: describe the changes made
- Be honest and specific - don't make up results
- Set "status" to "DONE" or use completion words when you believe the task is completed

"""

        # Add iteration context if applicable
        iteration = context.get('iteration', 0)
        max_iterations = context.get('max_iterations', 5)
        auditor_feedback = context.get('auditor_feedback')

        if iteration > 0 and auditor_feedback:
            iteration_context = f"""\n\n[Iteration {iteration + 1}/{max_iterations}]\nPrevious attempts did not complete the task. Try again with a different approach.

AUDITOR FEEDBACK:
{auditor_feedback}
"""
            return header_template + iteration_context + f"\nComplete this task:\n{task}"
        else:
            return header_template + f"Complete this task:\n{task}"

    def _format_auditor_prompt(self, task: str, header: str, context: Dict, system_instructions: str) -> str:
        """Format auditor prompt with XML structure."""
        header = header or "oneshot auditor"

        worker_result = context.get('worker_result', '(No worker output found)')

        prompt = f"""{header}

{system_instructions}

TASK:
{task}

WORK RESULT:
{worker_result}

Your verdict must be one of:
- "DONE": The task has been completed successfully.
- "RETRY": The task is incomplete. Ask the worker to try again.
- "IMPOSSIBLE": The task cannot be completed (missing resources, permissions denied, etc.).

Respond with ONLY your verdict and a brief explanation."""

        return prompt